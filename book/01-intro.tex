
\chapter{탐색적 자료 분석}
\label{intro}
이 책의 주요 논지는 실용적인 방법과 결합된 데이터가 질문에 대답하고, 불확실성하에서 의사결정을 안내하는 것이다.

한가지 사례로, 집사람과 함께 첫번째 아이를 기대할 때 전해들은 질문에 모디브를 얻어 한가지 사례 연구를 제시한다: 첫째 애기는 늦게 낳는 경향이 있을까요?  
\index{첫째 아이 (first babies)}

만약 이 질문을 구글에 검색하면, 상당한 토론글을 볼 수 있다. 몇몇 사람은 사실이라고하고, 다른 사람은 미신이라고 하고,
다른 사람은 첫째 얘들이 일찍 나온다고 애둘러 말하곤 한다. 

많은 토론글에서, 사람들은 자신의 주장을 뒷받침하기 위해서 데이터를 제공한다. 다음과 같은 많은 사례를 찾아볼 수 있다.


\begin{quote}

``최근에 첫째 아이를 출산한 내 친구 두명은 모두 자연분만 혹은 제왕절개하기 전에 예정일에서 거의 2주나 지났다.''


``첫째는 2주 늦게 나왔고 이제 생각하기에 둘째는 2주 빨리 나올것 같다.!!''

``제 생각에는 사실이 아니라고 생각하는데 왜냐하면 언니가 엄마의 첫째인데 다른 많은 사촌과 마찬가지로 빨리 나왔기 때문이다.''

\end{quote}

이와 같은 보고를 {\bf 일화적 증거(anecdotal evidence)}라고 부르는데, 이유는 논문으로 출판되지 않고 대체로 개인적인 데이터에 기반하고 있기 때문이다. 일상적인 대화에서, 일화와 관련해서 잘못된 것은 없다. 그래서 인용한 사람을 콕 집어서 뭐라고 할 의도는 없다.
\index{일화적 증거(anecdotal evidence)}

하지만, 좀더 설득적인 증거와, 좀더 신빙성있는 답을 원할지도 모른다. 이런 기준으로 본다면, 일화적 증거는 대체로 성공적이지 못하다. 왜냐하면:

\begin{itemize}

\item 적은 관측치(Small number of observations): 만약 첫째 아기에 대해서 임신 기간이 좀더 길다면, 아마도 차이는 자연적인 변동과 비교하여 적을 것이다. 이 경우에, 차이가 존재한다는 것을 확실히 하기 위해서는 많은 임신 사례를 비교해야할 것이다. 
\index{임신기간 (pregnancy length)}

\item 선택 편의(Selection bias): 임신기간에 관한 토론에 참가한 사람들은 첫째 아이가 늦게 태어났기 때문에 관심이 있을 수 있다. 이 경우에 데이터를 선택하는 과정이 결과를 왜곡할 수도 있다.
\index{선택 편의(selection bias)}
\index{편의(bias)!선택(selection)}

\item 확증 편의(Confirmation bias): 주장을 믿는 사람들은 주장을 확증해주는 사례에 좀더 기여할 듯 하다. 주장에 의구심을 갖는 사람들은  반례를 좀더 들것 같다. 
\index{확증 편의 (confirmation bias)}
\index{편의(bias)!확증(confirmation)}

\item 부정확(Inaccuracy): 일화는 종종 개인 이야기로, 기억이 부정확하고, 잘못 표현되며, 부정확하게 반복된다. 

\end{itemize}

그렇다면, 어떻게 더 잘 할 수 있을까요?


\section{통계적 접근방법}

일화적 접근법의 한계를 극복하기 위해서 통계도구를 사용하는데 다음을 포함한다:

\begin{itemize}

\item 자료 수집(Data collection): 
  대규모 국가적 조사에서 나온 자료를 사용한다. 통상 국가적 조사는 명시적으로 U.S 모집단에 대한 
  통계적으로 타당한 추론을 도출하도록 설계된다.
\index{자료 수집 (data collection)}

\item 기술통계(Descriptive statistics): 
  데이터를 간결하게 요약하는 통계량을 생성하고 다른 방식으로 평가하는데 데이터를 시각화한다.
\index{기술 통계 (descriptive statistics)}

\item 탐색적 데이터 분석 (Exploratory data analysis): 
  관심있는 질문을 다룰 수 있는 패턴, 차이점, 다른 특징을 찾는다. 
  동시에 일관되지 못함을 점검하고 한계를 식별한다.
\index{탐색적 데이터 분석 (exploratory data analysis)}

\item 추정(Estimation): 
  일반적인 모집단의 특징을 추정하는데 샘플에서 추출된 데이터를 사용한다.
\index{추정 (estimation)}

\item 가설 검증 (Hypothesis testing): 
  두 그룹간에 차이처럼 명백한 효과를 확인하는데 있어서 효과가 우연히 발생했는지 평가한다.
\index{가설 검증 (hypothesis testing)}

\end{itemize}

함정에 빠지는 것을 피하기 위해서 상기 단계를 조심스럽게 밟아서 좀더 당위성을 가지고 좀더 옳을 것 같은 결론에 도달할 수 있다.


\section{가족 성장 국가 조사 (National Survey of Family Growth)}
\label{nsfg}

1973년 이래로 미국 질병 통제예방 센터 (Disease Control and Prevention, CDC)에서 
가족 성장 국가 조사 (National Survey of Family Growth, NSFG)를 수행하고 있다.
조사 목적은 ``가족 생활, 결혼 및 이혼, 임신, 출산, 피임, 그리고 남녀 건강에 대한 정보를 수집하고,''
조사 결과는 ``건강 서비스 및 건강 교육 프로그램, 그리고 가족, 출산, 건강에 대한 통계적 조사를 수행''하는데 사용된다.
자세한 사항은 다음 웹사이트를 참조한다. \url{http://cdc.gov/nchs/nsfg.htm}.
\index{가족 성장 국가 조사 (National Survey of Family Growth)}
\index{NSFG}

첫째 아이가 늦게 낳는지와 다른 문제를 조사하려고 상기 조사로 수집된 데이터를 사용한다.
데이터를 효과적으로 사용하기 위해서는, 조사 설계(design of the study)를 이해할 필요가 있다.

NSFG는 {\bf 횡단적 연구(cross-sectional study)}로 특정 시점에 한 집단에 대한 스냅샷 정보를 수집한다.
가장 흔한 대안 연구는 {\bf 종단적 연구(longitudinal study)}로 한 집단을 여러 시점에 걸쳐 반복적으로 관찰하는 것이다. 

\index{횡단적 연구 (cross-sectional study)}
\index{연구 (study)!횡단(cross-sectional)}
\index{종단적 연구 (longitudinal study)}
\index{연구 (study)!종단 (longitudinal)}

NSFG는 7번 조사를 수행했다; 각 조사 전개를 {\bf 사이클(cycle)}이라고 한다. 
2002년 1월에서 2003년 3월까지 수행된 여섯번째 사이클에서 나온 데이터를 사용한다.  

\index{사이클 (cycle)}

조사 목적은 {\bf 모집단(population)}에 대한 결론을 도출하는 것으로, NSFG 목표 모집단은 15-44 연령의 미국민이다.
이상적으로 데이터를 전체 모집단의 모든 사람에게서 데이터를 수집하여야 하지만, 현실적으로 불가능하다.
대신에 {\bf 표본(sample)}으로 불리는 모집단의 일부에서 데이터를 수집한다.
조사에 참여한 사람을 {\bf 응답자(respondents)}라고 부른다.

\index{모집단 (population)}

일반적으로 종단적 연구는 {\bf 대표성(representative)}을 가져야 하는데 목표 모집단의 모든 멤버가 동일한 참여 가능성을 가져야한다는 의미다. 이러한 이상은 실무에서 달성하기는 어렵다. 하지만 조사를 수행함에 있어 최대한 근접하도록 노력해야 한다.

\index{응답자 (respondent)} 
\index{대표성 (representative)}

NSFG는 대표적이지 않다; 대신에 의도적으로 {\bf 오버샘플링(oversampling)}했다.
조사 설계자가 세 집단 (히스패닉, 흑인, 10대)에 대해서 미국인구에서 차지하는 것보다 높은 비율로 조사를 실시한다.
사유는 유효한 통계적 추론을 이끌어 내기 위해서 각 그룹에 대해 충분이 큰 응답자를 확보하기 위해서다.

\index{오버샘플링 (oversampling)}

물론, 오버샘플링 단점은 조사로부터 나온 통계량에 기반하여 일반 모집단에 대한 결론을 도출하기는 쉽지 않다. 
나중에 이점에 대해서는 다시 다룰 것이다.

이러한 유형의 데이터를 작업할 때, {\bf 코드북(codebook)}과 친근해지는 것이 중요하다.
코드북은 조사 서례, 조사 질문, 응답자 기록을 문서화한다. 코드북과 NSFG 데이터에 대한 사용자 가이드는 웹사이트에서 찾아볼 수 있다. \url{http://www.cdc.gov/nchs/nsfg/nsfg_cycle6.htm}


\section{데이터 가져오기}

이 책에 사용된 코드와 데이터는 \url{https://github.com/AllenDowney/ThinkStats2} 사이트에서 사용할 수 있다.
다운로드와 코드로 작업하는 것에 대한 자세한 정보는 ~\ref{code}을 참조한다.

코드를 다운로드하면, {\tt ThinkStats2/code/nsfg.py}이라는 파일이 있다. 
실행하면, 데이터 파일을 읽고, 몇가지 테스트를 수행하고, ``All tests passed.'' 라는 메시지를 출력한다.
\begin{verbatim}
$ python nsfg.py
(13593, 244)
nsfg.py: All tests passed.
\end{verbatim}

프로그램이 무엇을 수행하는지 살펴보자. NSFG 6번째 사이클에서 임신 데이터는 파일명이 {\tt 2002FemPreg.dat.gz}이다.
고정폭 칼럼을 가진 일반 텍스트(ASCII) 파일형식으로 gzip으로 압축되어 있다. 
파일 각각 라인은 한개 임신에 대한 데이터를 포함하는 {\bf 레코드(record)}가 된다.

파일 형식(format)은 {\tt 2002FemPreg.dct} 파일에 문서화되어 기술되어 있고 Stata 딕셔너리 파일이다.
Stata는 통계 소프트웨어 시스템 (통계 팩키지)의 일종으로 이러한 맥락에서 ``딕셔너리''는 각 행마다 각 변수의 위치를 식별하는데 사용되는 인덱스, 형식, 변수명 목록 정보를 담고 있다.  

예를 들어 {\tt 2002FemPreg.dct} 파일에서 몇줄이 다음에 있다.

%
\begin{verbatim}
infile dictionary {
  _column(1)  str12  caseid    %12s  "RESPONDENT ID NUMBER"
  _column(13) byte   pregordr   %2f  "PREGNANCY ORDER (NUMBER)"
}
\end{verbatim}

딕셔너리는 변수 두개를 기술한다: {\tt caseid}는 응답자 ID를 대표하는 12 자리 문자로 된 문자열이다;
 {\tt pregorder}는 1 바이트 정수형으로 응답자에 대한 임신 정보를 나타낸다.

다운로드한 코드에는 {\tt thinkstats2.py} 파일이 있는데 파이썬 모듈로 이 책에서 사용되는 많은 클래스와 함수를 포함하고 있다. 
Stata 딕셔너리와 NSFG 데이터 파일을 읽어 들일 수 있다. 다음에 {\tt nsfg.py} 프로그램에서 어떻게 사용되는지 사용례가 있다.

\begin{verbatim}
def ReadFemPreg(dct_file='2002FemPreg.dct',
                dat_file='2002FemPreg.dat.gz'):
    dct = thinkstats2.ReadStataDct(dct_file)
    df = dct.ReadFixedWidth(dat_file, compression='gzip')
    CleanFemPreg(df)
    return df
\end{verbatim}

{\tt ReadStataDct}은 딕셔너리 파일이름을 받아서 {\tt dct}를 반환한다.
{\tt dct}는 딕셔너리에서 받은 정보를 담고 있는 {\tt FixedWidthVariables} 객체다.
{\tt dct}는 데이터 파일을 읽는 {\tt FixedWidthVariables}을 제공한다.

\section{데이터프레임(DataFrames)}
\label{dataframe}

{\tt ReadFixedWidth} 결과는 데이터프레임(DataFrame)으로 판다스(pandas)에서 제공하는 가장 근원적인 자료구조다. 판다스는 이 책에서 사용하는 파이썬 자료 및 통계 팩키지 이름이다. 데이터프레임은 각 레코드마다 행(이 경우에 각 임신마다 한 행이 됨)과 각 변수에 대한 열을 포함하고 있다. 

\index{판다스 (pandas)}
\index{데이터프레임 (DataFrame)}

데이터외에 데이터프레임은 변수명과 변수 자료형을 포함하고 있으며, 데이터에 접근 및 변경하는 방법을 제공한다. 

{\tt df}를 출력하면, 행과 열, 데이터프레임 모양(13593 행/레코드, 244 열/변수)에 대한 잘려진 일부를 볼 수 있다. 

\begin{verbatim}
>>> import nsfg
>>> df = nsfg.ReadFemPreg()
>>> df
...
[13593 rows x 244 columns]
\end{verbatim}

{\tt columns} 속성은 유니코드 문자열로 칼럼명 시퀀스(sequence)를 반환한다. 

\begin{verbatim}
>>> df.columns
Index([u'caseid', u'pregordr', u'howpreg_n', u'howpreg_p', ... ])
\end{verbatim}

결과는 인덱스(Index)로 또다른 판다스 자료구조다. 추후 인덱스(Index)에 관해서 좀더 배울 것이지만, 지금은 리스트처럼 다루기로 한다.

\index{판다스 (pandas)}
\index{인덱스 (Index)}

\begin{verbatim}
>>> df.columns[1]
'pregordr'
\end{verbatim}

데이터프레임 칼럼에 접근하기 위해서는 칼럼이름을 키(key)로 사용할 수도 있다.

\index{데이터프레임 (DataFrame)}

\begin{verbatim}
>>> pregordr = df['pregordr']
>>> type(pregordr)
<class 'pandas.core.series.Series'>
\end{verbatim}

결과는 시리즈(Series)로 또다른 판다스 자료구조다. 시리즈는 몇가지 추가 기능을 가진 파이썬 리스트다. 시리즈를 출력하면, 인덱스와 상응하는 값이 출력된다. 

\index{시리즈 (Series)}

\begin{verbatim}
>>> pregordr
0     1
1     2
2     1
3     2
...
13590    3
13591    4
13592    5
Name: pregordr, Length: 13593, dtype: int64
\end{verbatim}

상기 예제에서, 인덱스는 0에서 13592 정수형 자료지만, 일반적으로 정렬가능한 임의의 자료형도 가능하다. 요소값도 정수형이지만, 임의의 자료형도 가능하다.

마지막 행은 변수명, 시리즈 길이, 그리고 자료형 정보가 있다; {\tt int64}은 NumPy에서 제공하는 자료형 중의 하나다. 만약 32-비트 컴퓨터에서 상기 예제를 실행한다면, {\tt int32}가 출력된다.
\index{넘파이 (NumPy)}

정수 인덱스와 슬라이스(slice)를 사용해서 시리즈 요소값(element)에 접근할 수 있다.

\begin{verbatim}
>>> pregordr[0]
1
>>> pregordr[2:5]
2    1
3    2
4    3
Name: pregordr, dtype: int64
\end{verbatim}

인덱스 연산자 실행 결과는 {\tt int64}이고, 슬라이스 연산자 결과는 또 다른 시리즈다. 

점 표기법(dot notation)을 사용해서 데이터프레임 칼럼을 접근할 수도 있다.

\index{데이터프레임 (DataFrame)}

\begin{verbatim}
>>> pregordr = df.pregordr
\end{verbatim}

칼럼명이 유효한 파이썬 식별자라면 이 표기법은 잘 동작한다. 그래서 문자로 시작해야 하고, 공백을 포함하지 말아야 하고 등등을 지켜줘야 있다.  
\section{변수 (Variables)}

NSFG 데이터셋에서 이미 변수 두개, {\tt caseid}와 {\tt pregordr}을 살펴봤다. 전체적으로 244개 변수가 있다는 것도 확인했다. 책에서 탐색적 자료분석으로 다음 변수를 사용한다.

\begin{itemize}

\item {\tt caseid}는 응답자의 정수형 ID다.

\item {\tt prglngth}는 정수형으로 주로 임신 기간을 나타낸다.
\index{임신 기간 (pregnancy length)}

\item {\tt outcome}은 출산 결과에 대한 정수형 코드값이다. 코드값 1 은 정상출산을 나타낸다.

\item {\tt pregordr}은 임신 일련번호다; 예를 들어, 응답자의 첫번째 임신 코드값은 1, 두번째 임신 코드값은 2, 등등.

\item {\tt birthord}는 정상출산에 대한 일련번호다; 응답자의 첫번째 아이 코드값은 1 등등. 정상출산이 아닌 경우에는 필드값이 공백이다. 


\item \verb"birthwgt_lb"와 \verb"birthwgt_oz"은 출산시 아이 체중에 대한 파운드와 온스 정보를 담고 있다.

\index{출산 체중 (birth weight)}
\index{체중 (weight)!출산 (birth)}

\item {\tt agepreg}는 임신 후기 산모 나이를 나타낸다.

\item {\tt finalwgt}는 응답자와 연관된 통계적 가중치다. 부동소수점 값으로 응답자가 대표하는 미국 인구중에 비중을 나타낸다.

\index{가중치 (weight)!표본 (sample)}

\end{itemize}

주의깊이 코드북을 읽게되면, 변수 중의 상당수가 {\bf 재코드(recodes)}된 것을 볼 수 있는데 조사에서 수집된 {\bf 원자료 (raw data)} 일부분은 아니다. 재코드된 변수는 원자료를 이용하여 계산된 것이다.
\index{재코드 (recode)} 
\index{원자료 (raw data)}

예를 들어, 정상출산에 대한 {\tt prglngth} 변수는 만약 있다면 {\tt wksgest} (회임기간 주차 정보)와 동일하다; 만약 회임기간 정보가 없다면 {\tt mosgest * 4.33} 공식(회임기간 월차 정보 곱하기 한달 평균 주차 정보)을 사용해서 추정한다. 

재코드는 자료 정합성과 일관성을 점검하는 로직에 기반한다. 스스로 원자료를 처리할 납득이갈만한 이유가 없다면, 일반적으로 재코드된 자료가 있다면 그대로 사용하는 것이 좋은 생각이다. 

\section{변환 (Transformation)}
\label{cleaning}

이와 같이 데이터를 가져올 때, 오류를 점검하고, 특수값을 처리하고, 데이터를 다른 형식으로 변환하고, 계산을 수행해야 한다. 이와 같은 작업을 통상 {\bf 데이터 정제(data cleaning)}라고 부른다.

{\tt nsfg.py}는 {\tt CleanFemPreg} 함수가 있어서 사용할 변수를 사전에 정제한다.

\begin{verbatim}
def CleanFemPreg(df):
    df.agepreg /= 100.0

    na_vals = [97, 98, 99]
    df.birthwgt_lb.replace(na_vals, np.nan, inplace=True)
    df.birthwgt_oz.replace(na_vals, np.nan, inplace=True)

    df['totalwgt_lb'] = df.birthwgt_lb + df.birthwgt_oz / 16.0    
\end{verbatim}

{\tt agepreg} 변수는 임신 말기에 산모 나이정보를 담고 있다. 
데이터 파일에서 {\tt agepreg} 변수는 백분의 정수로 인코딩되어 있다.
그래서 첫번째은 100으로 {\tt agepreg} 변수를 나눠서 연도로 부동소수점 값을 생성한다.

\verb"birthwgt_lb"와 \verb"birthwgt_oz" 변수는 정상출산 임신에 대한 
신생아의 체중으로 파운드와 온스 표현된 정보를 담고 있다. 
추가로 몇몇 특수값도 있다.

\begin{verbatim}
97	NOT ASCERTAINED
98	REFUSED	 
99	DON'T KNOW
\end{verbatim}

숫자 부호로 표현된 특수값은 {\em 위험}한데, 이유는 만약 적절하게 처리되지 않는다면,
99 파운드 신생아처럼 가공된 결과를 생성할 수 있다. 
{\tt replace} 메쏘드는 특수값을 {\tt np.nan}으로 바꾼다. {\tt np.nan}는 
``not a number.''를 나타내는 특수 부동소수점값이다. 
{\tt inplace} 플래그는 {\tt replace}에 새로운 시리즈를 생성하는 대신에 
기존 시리즈를 변경하게 한다.

\index{NaN}

IEEE 부동소수점 표준의 일부분으로, 만약 인자중 하나가 {\tt nan} 이면,
모든 수학 연산은 {\tt nan}을 반환한다.

\begin{verbatim}
>>> import numpy as np
>>> np.nan / 100.0
nan
\end{verbatim}

그래서, {\tt nan}으로 연산한 것은 올바른 연산을 하고, 대부분의 판다스 함수는
{\tt nan}을 적절하게 다룬다. 하지만 결측값(missing value)을 다루는 것은 반복되는 이슈가 된다.

\index{판다스 (pandas)}
\index{결측값 (missing values)}

{\tt CleanFemPreg} 함수 마지막 줄은 파운드와 온스를 하나의 값, 
파운드로 조합하는 새로운 칼럼 \verb"totalwgt_lb"을 생성한다.

중요한 사항: 데이터프레임에 새로운 칼럼을 추가할 때, 다음과 같은 딕셔너리 구문을 사용해야 한다.

\index{데이터프레임 (DataFrame)}

\begin{verbatim}
    # CORRECT
    df['totalwgt_lb'] = df.birthwgt_lb + df.birthwgt_oz / 16.0 
\end{verbatim}

다음과 같은 점표기법은 안된다.

\begin{verbatim}
    # WRONG!
    df.totalwgt_lb = df.birthwgt_lb + df.birthwgt_oz / 16.0 
\end{verbatim}

점표기법 버젼은 데이터프레임 객체에 속성을 추가하지만, 
그 속성이 새로운 칼럼으로 다뤄지는 것은 아니다.

\section{타당성 (Validation)}

When data is exported from one software environment and imported into
another, errors might be introduced.  And when you are
getting familiar with a new dataset, you might interpret data
incorrectly or introduce other misunderstandings.  If you take
time to validate the data, you can save time later and avoid errors.

One way to validate data is to compute basic statistics and compare
them with published results.  For example, the NSFG codebook includes
tables that summarize each variable.  Here is the table for
{\tt outcome}, which encodes the outcome of each pregnancy:

\begin{verbatim}
value	label	 	        Total
1	LIVE BIRTH              9148
2	INDUCED ABORTION        1862
3	STILLBIRTH               120
4	MISCARRIAGE             1921
5	ECTOPIC PREGNANCY        190
6	CURRENT PREGNANCY        352
\end{verbatim}

The Series class provides a method, \verb"value_counts", that
counts the number of times each value appears.  If we select the {\tt
  outcome} Series from the DataFrame, we can use \verb"value_counts"
to compare with the published data:
\index{DataFrame}
\index{Series}

\begin{verbatim}
>>> df.outcome.value_counts().sort_index()
1    9148
2    1862
3     120
4    1921
5     190
6     352
\end{verbatim}

The result of \verb"value_counts" is a Series;
\verb"sort_index" sorts the Series by index, so the
values appear in order.

Comparing the results with the published table, it looks like the
values in {\tt outcome} are correct.  Similarly, here is the published
table for \verb"birthwgt_lb"

\begin{verbatim}
value	label                  Total
.	INAPPLICABLE            4449
0-5	UNDER 6 POUNDS          1125
6	6 POUNDS                2223
7	7 POUNDS                3049
8	8 POUNDS                1889
9-95	9 POUNDS OR MORE         799
\end{verbatim}

And here are the value counts:

\begin{verbatim}
>>> df.birthwgt_lb.value_counts().sort_index()
0        8
1       40
2       53
3       98
4      229
5      697
6     2223
7     3049
8     1889
9      623
10     132
11      26
12      10
13       3
14       3
15       1
51       1
\end{verbatim}

The counts for 6, 7, and 8 pounds check out, and if you add
up the counts for 0-5 and 9-95, they check out, too.  But
if you look more closely, you will notice one value that has to be
an error, a 51 pound baby!

To deal with this error, I added a line to {\tt CleanFemPreg}:

\begin{verbatim}
df.birthwgt_lb[df.birthwgt_lb > 20] = np.nan
\end{verbatim}

This statement replaces invalid values with {\tt np.nan}.
The expression in brackets yields a Series of type {\tt bool}, 
where True indicates that the condition is true.  When a boolean
Series is used as an index, it selects only the elements that
satisfy the condition.
\index{Series}
\index{boolean}
\index{NaN}


\section{Interpretation}

To work with data effectively, you have to think on two levels at the
same time: the level of statistics and the level of context.

As an example, let's look at the sequence of outcomes for a few
respondents.  Because of the way the data files are organized, we have
to do some processing to collect the pregnancy data for each respondent.
Here's a function that does that:

\begin{verbatim}
def MakePregMap(df):
    d = defaultdict(list)
    for index, caseid in df.caseid.iteritems():
        d[caseid].append(index)
    return d
\end{verbatim}

{\tt df} is the DataFrame with pregnancy data.  The {\tt iteritems}
method enumerates the index (row number)
and {\tt caseid} for each pregnancy.
\index{DataFrame}

{\tt d} is a dictionary that maps from each case ID to a list of
indices.  If you are not familiar with {\tt defaultdict}, it is in
the Python {\tt collections} module.
Using {\tt d}, we can look up a respondent and get the
indices of that respondent's pregnancies.

This example looks up one respondent and prints a list of outcomes
for her pregnancies:

\begin{verbatim}
>>> caseid = 10229
>>> indices = preg_map[caseid]
>>> df.outcome[indices].values
[4 4 4 4 4 4 1]
\end{verbatim}

{\tt indices} is the list of indices for pregnancies corresponding
to respondent {\tt 10229}.

Using this list as an index into {\tt df.outcome} selects the
indicated rows and yields a Series.  Instead of printing the
whole Series, I selected the {\tt values} attribute, which is
a NumPy array.  
\index{NumPy}
\index{Series}

The outcome code {\tt 1} indicates a live birth. Code {\tt 4} indicates
a miscarriage; that is, a pregnancy that ended spontaneously, usually
with no known medical cause.

Statistically this respondent is not unusual.  Miscarriages are common
and there are other respondents who reported as many or more.

But remembering the context, this data tells the story of a woman who
was pregnant six times, each time ending in miscarriage.  Her seventh
and most recent pregnancy ended in a live birth.  If we consider this
data with empathy, it is natural to be moved by the story it tells.

Each record in the NSFG dataset represents a person who provided
honest answers to many personal and difficult questions.  We can use
this data to answer statistical questions about family life,
reproduction, and health.  At the same time, we have an obligation
to consider the people represented by the data, and to afford them
respect and gratitude.
\index{ethics}


\section{Exercises}

\begin{exercise}
In the repository you downloaded, you should find a file named
\verb"chap01ex.ipynb", which is an IPython notebook.  You can
launch IPython notebook from the command line like this:
\index{IPython}

\begin{verbatim}
$ ipython notebook &
\end{verbatim}

If IPython is installed, it should launch a server that runs in the
background and open a browser to view the notebook.  If you are not
familiar with IPython, I suggest you start at
\url{http://ipython.org/ipython-doc/stable/notebook/notebook.html}.

You can add a command-line option that makes figures appear ``inline'';
that is, in the notebook rather than a pop-up window:

\begin{verbatim}
$ ipython notebook --pylab=inline &
\end{verbatim}

Open \verb"chap01ex.ipynb".  Some cells are already filled in, and
you should execute them.  Other cells give you instructions for
exercises you should try.

A solution to this exercise is in \verb"chap01soln.ipynb"
\end{exercise}


\begin{exercise}
Create a file named \verb"chap01ex.py" and write code that reads
the respondent file, {\tt 2002FemResp.dat.gz}.  You might want to
start with a copy of {\tt nsfg.py} and modify it.

The variable {\tt pregnum} is a recode that indicates how many
times each respondent has been pregnant.  Print the value counts
for this variable and compare them to the published results in
the NSFG codebook.

You can also cross-validate the respondent and pregnancy files by
comparing {\tt pregnum} for each respondent with the number of
records in the pregnancy file.

You can use {\tt nsfg.MakePregMap} to make a dictionary that maps
from each {\tt caseid} to a list of indices into the pregnancy
DataFrame.
\index{DataFrame}

A solution to this exercise is in \verb"chap01soln.py"
\end{exercise}


\begin{exercise}
The best way to learn about statistics is to work on a project you are
interested in.  Is there a question like, ``Do first babies arrive
late,'' that you want to investigate?

Think about questions you find personally interesting, or items of
conventional wisdom, or controversial topics, or questions that have
political consequences, and see if you can formulate a question that
lends itself to statistical inquiry.

Look for data to help you address the question.  Governments are good
sources because data from public research is often freely
available.  Good places to start include \url{http://www.data.gov/},
and \url{http://www.science.gov/}, and in the United Kingdom,
\url{http://data.gov.uk/}.

Two of my favorite data sets are the General Social Survey at
\url{http://www3.norc.org/gss+website/}, and the European Social
Survey at \url{http://www.europeansocialsurvey.org/}.

If it seems like someone has already answered your question, look
closely to see whether the answer is justified.  There might be flaws
in the data or the analysis that make the conclusion unreliable.  In
that case you could perform a different analysis of the same data, or
look for a better source of data.

If you find a published paper that addresses your question, you
should be able to get the raw data.  Many authors make their data
available on the web, but for sensitive data you might have to
write to the authors, provide information about how you plan to use
the data, or agree to certain terms of use.  Be persistent!

\end{exercise}


\section{Glossary}

\begin{itemize}

\item {\bf anecdotal evidence}: Evidence, often personal, that is collected
  casually rather than by a well-designed study.
\index{anecdotal evidence}

\item {\bf population}: A group we are interested in studying.
  ``Population'' often refers to a
  group of people, but the term is used for other subjects,
  too.
\index{population}

\item {\bf cross-sectional study}: A study that collects data about a
population at a particular point in time.
\index{cross-sectional study}
\index{study!cross-sectional}

\item {\bf cycle}: In a repeated cross-sectional study, each repetition
of the study is called a cycle.

\item {\bf longitudinal study}: A study that follows a population over
time, collecting data from the same group repeatedly.
\index{longitudinal study}
\index{study!longitudinal}

\item {\bf record}: In a dataset, a collection of information about
a single person or other subject.
\index{record}

\item {\bf respondent}: A person who responds to a survey.
\index{respondent}

\item {\bf sample}: The subset of a population used to collect data.
\index{sample}

\item {\bf representative}: A sample is representative if every member
of the population has the same chance of being in the sample.
\index{representative}

\item {\bf oversampling}: The technique of increasing the representation
of a sub-population in order to avoid errors due to small sample
sizes.
\index{oversampling}

\item {\bf raw data}: Values collected and recorded with little or no
checking, calculation or interpretation.
\index{raw data}

\item {\bf recode}: A value that is generated by calculation and other
logic applied to raw data.
\index{recode}

\item {\bf data cleaning}: Processes that include validating data,
  identifying errors, translating between data types and
  representations, etc.

\end{itemize}

