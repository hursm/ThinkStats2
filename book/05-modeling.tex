\chapter{분포 모형화 (Modeling distributions)}
\label{modeling}

지금까지 사용한 분포는 {\bf 경험적 분포 (empirical distributions)}라고 부른다.
이유는 필연적으로 유한 표본인 경험적 관측치에 기반하고 있기 때문이다.

\index{해석 분포 (analytic distribution)}
\index{분포 (distribution)!해석 (analytic)}
\index{경험적 분포 (empirical distribution)}
\index{분포 (distribution)!경험 (empirical)}

수학 함수인 CDF로 특징 지어지는 {\bf 해석 분포 (analytic distribution)}가 대안이 된다.
해석 분포가 경험적 분포를 모형화하는데 사용될 수 있다.
이러한 맥락에서 {\bf 모형(model)}은 불필요한 부분을 덜어낸 단순화가 된다.
이번 장에서 자주 사용되는 분포를 제시하고 이를 사용하여 다양한 출처를 가진 
데이터를 모형화한다.

\index{모형 (model)}

이번 장에서 사용되는 코드는 {\tt analytic.py}에 있다.
코드를 다운로드하고 작업하는 것에 대한 정보는 ~\ref{code}을 참조한다.


\section{지수분포 (exponential distribution)}
\label{exponential}
\index{지수분포 (exponential distribution)}
\index{분포 (distribution)!지수 (exponential)}

\begin{figure}
% analytic.py
%\centerline{\includegraphics[height=2.5in]{figs/analytic_expo_cdf.pdf}}
\caption{CDFs of exponential distributions with various parameters.}
\label{analytic_expo_cdf}
\end{figure}

{\bf 지수 분포 (exponential distribution)}로 시작하는데 이유는 상대적으로 단순하기 때문이다.
지수분포 CDF는 다음과 같다.
%
\[ \CDF(x) = 1 - e^{-\lambda x} \]
%

모수 $\lambda$가 분포 형상(shape)을 결정한다. 
그림~\ref{analytic_expo_cdf}에서 $\lambda = $ 0.5, 1, 2 값을 가진
CDF가 대략 모양이 어떤지 볼 수 있다.
\index{모수 (parameter)}

현실 세계에서 일련의 사건을 보고, 사건 간에 시간({\bf 도착간격 시간, interarrival times})을 측정할 때 지수분포가 등장한다.
만약 사건이 언제든지 균등하게 발생할 것 같다면 도착간격 시간 분포는 지수분포같은 경향이 있다.
\index{도착간격 시간 (interarrival time)}

일례로, 출생간 발생시간을 살펴보자. 1997년 12월 18일 호주 브리즈번
\footnote{예제에 나오는 자료와 정보는 저널 논문에 기반한다. Dunn, ``A Simple Dataset for Demonstrating Common Distributions,'' Journal of Statistics Education v.7, n.3 (1999)}
에서 44명 신생아가 출생했다. 모든 44명 신생아 출생 시간이 지역신문에 출간되었다;
전체 데이터셋은 {\tt ThinkStats2} 저장소 {\tt babyboom.dat} 파일에 담겨있다.
\index{출생 시간 (birth time)}
\index{호주 (Australia)} 
\index{브리즈번 (Brisbane)}

\begin{verbatim}
    df = ReadBabyBoom()
    diffs = df.minutes.diff()
    cdf = thinkstats2.Cdf(diffs, label='actual')

    thinkplot.Cdf(cdf)
    thinkplot.Show(xlabel='minutes', ylabel='CDF')
\end{verbatim}

{\tt ReadBabyBoom} 함수가 데이터 파일을 읽어들이고 {\tt time}, {\tt sex}, \verb"weight_g", {\tt minutes}
칼럼으로 구성된 데이터프레임을 반환한다.
여기서 {\tt minutes}가 자정 이후 출생시간을 분으로 변환한 시간정보를 담고 있다.
\index{데이터프레임 (DataFrame)}
\index{thinkplot}

\begin{figure}
% analytic.py
%\centerline{\includegraphics[height=2.5in]{figs/analytic_interarrivals.pdf}}
\caption{CDF of interarrival times (left) and CCDF on a log-y scale (right).}
\label{analytic_interarrival_cdf}
\end{figure}

%\begin{figure}
% analytic.py
%%\centerline{\includegraphics[height=2.5in]{figs/analytic_interarrivals_logy.pdf}}
%\caption{CCDF of interarrival times.}
%\label{analytic_interarrival_ccdf}
%\end{figure}

{\tt diffs}는 연속되는 출생시간 사이 차이가 되고 
{\tt cdf}는 출생간격 시간 분포가 된다.
그림~\ref{analytic_interarrival_cdf} (왼편)이 CDF를 나타낸다.
전형적인 지수분포 형상을 지닌 처럼 보이지만, 어떻게 분간할 수 있을까?

한 방법은 {\bf 보완 CDF (complementary CDF)}를 플롯으로 그리는 것이다.
보완 CDF는 log-y 척도로 $1 - \CDF(x)$이다.
지수분포 데이터에 대해서는 결과가 직선이다. 왜 그런지 살펴보자.

\index{보완 CDF (complementary CDF)} 
\index{CDF!보완 (complementary)} 
\index{CCDF}

독자가 생각하기에 지수분포를 따르는 데이터셋을 보완 CDF(CCDF) 플롯으로 그리면, 
다음과 같은 함수가 나올 것으로 기대한다.
%
\[ y \approx e^{-\lambda x} \]
%
양변에 로그를 취하면 다음과 같다.
%
\[ \log y \approx -\lambda x\]
%
그래서, log-y 척도로 CCDF는 기울기 $-\lambda$인 직선이 된다.
다음에 플롯을 생성하는 방법이 있다.
\index{로그 척도 (logarithmic scale)}
\index{보완 CDF (complementary CDF)}
\index{CDF!보완 (complementary)}
\index{CCDF}

\begin{verbatim}
    thinkplot.Cdf(cdf, complement=True)
    thinkplot.Show(xlabel='minutes',
                   ylabel='CCDF',
                   yscale='log')
\end{verbatim}

{\tt complement=True} 인자가 있어서, {\tt thinkplot.Cdf}이 플롯을 그리기 전에
보완 CDF를 계산한다. 그리고 {\tt yscale='log'}를 통해서  
{\tt thinkplot.Show}가 로그 척도로 {\tt y}축을 고정한다.
\index{thinkplot}
\index{Cdf}

그림~\ref{analytic_interarrival_cdf} (오른편)에 결과가 있다.
정확하게 직선이 아니다. 이 데이터에 대해서 완벽한 모델로 지수 분포가 아니라는 것이 표시된다.
기본 가정---출생이 아무 때고 균등하게 발생---이 정확하게 사실이 아닐 것이다.
그럼에도 불구하고 지수분포로 이 데이터셋을 모형화하는 것이 합리적일 것이다.
이와 같은 단순화로 단 하나의 모수로 분포를 요약할 수 있다.
\index{모형 (model)}

모수 $\lambda$가 율(rate)로 해석될 수 있다; 즉, 평균적으로 단위 시간에 
발생하는 사건 수. 예제에서 44명의 신생아가 24시간내에 태어난다.
그래서 율값이 분당 $\lambda = 0.0306$이 된다.
지수분포 평균은 $1/\lambda$ 으로 신생아 간에 출생 평균 시간은 32.7분이 된다.

\section{정규 분포 (normal distribution)}
\label{normal}

The {\bf normal distribution}, also called Gaussian, is commonly
used because it describes many phenomena, at least approximately.
It turns out that there is a good reason for its ubiquity, which we
will get to in Section~\ref{CLT}.
\index{CDF}
\index{parameter}
\index{mean}
\index{standard deviation}
\index{normal distribution}
\index{distribution!normal}
\index{Gaussian distribution}
\index{distribution!Gaussian}

%
%\[ \CDF(z) = \frac{1}{\sqrt{2 \pi}} \int_{-\infty}^z e^{-t^2/2} dt \]
%

\begin{figure}
% analytic.py
%\centerline{\includegraphics[height=2.5in]{figs/analytic_gaussian_cdf.pdf}}
\caption{CDF of normal distributions with a range of parameters.}
\label{analytic_gaussian_cdf}
\end{figure}

The normal distribution is characterized by two parameters: the mean,
$\mu$, and standard deviation $\sigma$.  The normal distribution with
$\mu=0$ and $\sigma=1$ is called the {\bf standard normal
  distribution}.  Its CDF is defined by an integral that does not have
a closed form solution, but there are algorithms that evaluate it
efficiently.  One of them is provided by SciPy: {\tt scipy.stats.norm}
is an object that represents a normal distribution; it provides a
method, {\tt cdf}, that evaluates the standard normal CDF:
\index{SciPy}
\index{closed form}

\begin{verbatim}
>>> import scipy.stats
>>> scipy.stats.norm.cdf(0)
0.5
\end{verbatim}

This result is correct: the median of the standard normal distribution
is 0 (the same as the mean), and half of the values fall below the
median, so $\CDF(0)$ is 0.5.

{\tt norm.cdf} takes optional parameters: {\tt loc}, which
specifies the mean, and {\tt scale}, which specifies the
standard deviation.

{\tt thinkstats2} makes this function a little easier to use
by providing {\tt EvalNormalCdf}, which takes parameters {\tt mu}
and {\tt sigma} and evaluates the CDF at {\tt x}:
\index{normal distribution}

\begin{verbatim}
def EvalNormalCdf(x, mu=0, sigma=1):
    return scipy.stats.norm.cdf(x, loc=mu, scale=sigma)
\end{verbatim}

Figure~\ref{analytic_gaussian_cdf} shows CDFs for normal
distributions with a range of parameters.  The sigmoid shape of these
curves is a recognizable characteristic of a normal distribution.

In the previous chapter we looked at the distribution of birth
weights in the NSFG.  Figure~\ref{analytic_birthwgt_model} shows the
empirical CDF of weights for all live births and the CDF of
a normal distribution with the same mean and variance.
\index{National Survey of Family Growth}
\index{NSFG}
\index{birth weight}
\index{weight!birth}

\begin{figure}
% analytic.py
%\centerline{\includegraphics[height=2.5in]{figs/analytic_birthwgt_model.pdf}}
\caption{CDF of birth weights with a normal model.}
\label{analytic_birthwgt_model}
\end{figure}

The normal distribution is a good model for this dataset, so
if we summarize the distribution with the parameters
$\mu = 7.28$ and $\sigma = 1.24$, the resulting error
(difference between the model and the data) is small.
\index{model}
\index{percentile}

Below the 10th percentile there is a discrepancy between the data
and the model; there are more light babies than we would expect in
a normal distribution.  If we are specifically interested in preterm
babies, it would be important to get this part of the distribution
right, so it might not be appropriate to use the normal
model.


\section{Normal probability plot}

For the exponential distribution, and a few others, there are
simple transformations we can use to test whether an analytic
distribution is a good model for a dataset.
\index{exponential distribution}
\index{distribution!exponential}
\index{model}

For the normal distribution there is no such transformation, but there
is an alternative called a {\bf normal probability plot}.  There
are two ways to generate a normal probability plot: the hard way
and the easy way.  If you are interested in the hard way, you can
read about it at \url{https://en.wikipedia.org/wiki/Normal_probability_plot}.
Here's the easy way:
\index{normal probability plot}
\index{plot!normal probability}
\index{normal distribution}
\index{distribution!normal}
\index{Gaussian distribution}
\index{distribution!Gaussian}

\begin{enumerate}

\item Sort the values in the sample.

\item From a standard normal distribution ($\mu=0$ and $\sigma=1$),
generate a random sample with the same size as the sample, and sort it.
\index{random number}

\item Plot the sorted values from the sample versus the random values.

\end{enumerate}

If the distribution of the sample is approximately normal, the result
is a straight line with intercept {\tt mu} and slope {\tt sigma}.
{\tt thinkstats2} provides {\tt NormalProbability}, which takes a
sample and returns two NumPy arrays:
\index{NumPy}

\begin{verbatim}
xs, ys = thinkstats2.NormalProbability(sample)
\end{verbatim}

\begin{figure}
% analytic.py
%\centerline{\includegraphics[height=2.5in]{figs/analytic_normal_prob_example.pdf}}
\caption{Normal probability plot for random samples from normal distributions.}
\label{analytic_normal_prob_example}
\end{figure}

{\tt ys} contains the sorted values from {\tt sample}; {\tt xs}
contains the random values from the standard normal distribution.

To test {\tt NormalProbability} I generated some fake samples that
were actually drawn from normal distributions with various parameters.
Figure~\ref{analytic_normal_prob_example} shows the results.
The lines are approximately straight, with values in the tails
deviating more than values near the mean.

Now let's try it with real data.  Here's code to generate
a normal probability plot for the birth weight data from the
previous section.  It plots a gray line that represents the model
and a blue line that represents the data.
\index{birth weight}
\index{weight!birth}

\begin{verbatim}
def MakeNormalPlot(weights):
    mean = weights.mean()
    std = weights.std()

    xs = [-4, 4]
    fxs, fys = thinkstats2.FitLine(xs, inter=mean, slope=std)
    thinkplot.Plot(fxs, fys, color='gray', label='model')

    xs, ys = thinkstats2.NormalProbability(weights)
    thinkplot.Plot(xs, ys, label='birth weights')
\end{verbatim}

{\tt weights} is a pandas Series of birth weights;
{\tt mean} and {\tt std} are the mean and standard deviation.
\index{pandas}
\index{Series}
\index{thinkplot}
\index{standard deviation}

{\tt FitLine} takes a sequence of {\tt xs}, an intercept, and a
slope; it returns {\tt xs} and {\tt ys} that represent a line
with the given parameters, evaluated at the values in {\tt xs}.

{\tt NormalProbability} returns {\tt xs} and {\tt ys} that
contain values from the standard normal distribution and values
from {\tt weights}.  If the distribution of weights is normal,
the data should match the model.
\index{model}

\begin{figure}
% analytic.py
%\centerline{\includegraphics[height=2.5in]{figs/analytic_birthwgt_normal.pdf}}
\caption{Normal probability plot of birth weights.}
\label{analytic_birthwgt_normal}
\end{figure}

Figure~\ref{analytic_birthwgt_normal} shows the results for
all live births, and also for full term births (pregnancy length greater
than 36 weeks).  Both curves match the model near the mean and
deviate in the tails.  The heaviest babies are heavier than what
the model expects, and the lightest babies are lighter.
\index{pregnancy length}

When we select only full term births, we remove some of the lightest
weights, which reduces the discrepancy in the lower tail of the
distribution.

This plot suggests that the normal model describes the distribution
well within a few standard deviations from the mean, but not in the
tails.  Whether it is good enough for practical purposes depends
on the purposes.
\index{model}
\index{birth weight}
\index{weight!birth}
\index{standard deviation}


\section{The lognormal distribution}
\label{brfss}
\label{lognormal}

If the logarithms of a set of values have a normal distribution, the
values have a {\bf lognormal distribution}.  The CDF of the lognormal
distribution is the same as the CDF of the normal distribution,
with $\log x$ substituted for $x$.
%
\[ CDF_{lognormal}(x) = CDF_{normal}(\log x)\]
%
The parameters of the lognormal distribution are usually denoted
$\mu$ and $\sigma$.  But remember that these parameters are {\em not}
the mean and standard deviation; the mean of a lognormal distribution
is $\exp(\mu +\sigma^2/2)$ and the standard deviation is
ugly (see \url{http://wikipedia.org/wiki/Log-normal_distribution}).
\index{parameter} \index{weight!adult} \index{adult weight}
\index{lognormal distribution}
\index{distribution!lognormal}
\index{CDF}

\begin{figure}
% brfss.py
%\centerline{
%\includegraphics[height=2.5in]{figs/brfss_weight.pdf}}
%\caption{CDF of adult weights on a linear scale (left) and
%log scale (right).}
%\label{brfss_weight}
\end{figure}

If a sample is approximately lognormal and you plot its CDF on a
log-x scale, it will have the characteristic shape of a normal
distribution.  To test how well the sample fits a lognormal model, you
can make a normal probability plot using the log of the values
in the sample.
\index{normal probability plot}
\index{model}

As an example, let's look at the distribution of adult weights, which
is approximately lognormal.\footnote{I was tipped off to this
  possibility by a comment (without citation) at
  \url{http://mathworld.wolfram.com/LogNormalDistribution.html}.
  Subsequently I found a paper that proposes the log transform and
  suggests a cause: Penman and Johnson, ``The Changing Shape of the
  Body Mass Index Distribution Curve in the Population,'' Preventing
  Chronic Disease, 2006 July; 3(3): A74.  Online at
  \url{http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1636707}.}

The National Center for Chronic Disease
Prevention and Health Promotion conducts an annual survey as part of
the Behavioral Risk Factor Surveillance System
(BRFSS).\footnote{Centers for Disease Control and Prevention
  (CDC). Behavioral Risk Factor Surveillance System Survey
  Data. Atlanta, Georgia: U.S. Department of Health and Human
  Services, Centers for Disease Control and Prevention, 2008.}  In
2008, they interviewed 414,509 respondents and asked about their
demographics, health, and health risks.
Among the data they collected are the weights in kilograms of
398,484 respondents.
\index{Behavioral Risk Factor Surveillance System}
\index{BRFSS}

The repository for this book contains {\tt CDBRFS08.ASC.gz},
a fixed-width ASCII file that contains data from the BRFSS,
and {\tt brfss.py}, which reads the file and analyzes the data.

\begin{figure}
% brfss.py
%\centerline{
%\includegraphics[height=2.5in]{figs/brfss_weight_normal.pdf}}
\caption{Normal probability plots for adult weight on a linear scale
  (left) and log scale (right).}
\label{brfss_weight_normal}
\end{figure}

Figure~\ref{brfss_weight} (left) shows the distribution of adult
weights on a linear scale with a normal model.
Figure~\ref{brfss_weight} (right) shows the same distribution on a log
scale with a lognormal model.  The lognormal model is a better fit,
but this representation of the data does not make the difference
particularly dramatic.  \index{respondent} \index{model}

Figure~\ref{brfss_weight_normal} shows normal probability plots for
adult weights, $w$, and for their logarithms, $\log_{10} w$.  Now it
is apparent that the data deviate substantially from the normal model.
On the other hand, the lognormal model is a good match for the data.
\index{normal distribution} \index{distribution!normal}
\index{Gaussian distribution} \index{distribution!Gaussian}
\index{lognormal distribution} \index{distribution!lognormal}
\index{standard deviation} \index{adult weight} \index{weight!adult}
\index{model} \index{normal probability plot}


\section{The Pareto distribution}
\index{Pareto distribution}
\index{distribution!Pareto}
\index{Pareto, Vilfredo}

The {\bf Pareto distribution} is named after the economist Vilfredo Pareto,
who used it to describe the distribution of wealth (see
\url{http://wikipedia.org/wiki/Pareto_distribution}).  Since then, it
has been used to describe phenomena in the natural and social sciences
including sizes of cities and towns, sand particles and meteorites,
forest fires and earthquakes.  \index{CDF}

The CDF of the Pareto distribution is:
%
\[ CDF(x) = 1 - \left( \frac{x}{x_m} \right) ^{-\alpha} \]
%
The parameters $x_{m}$ and $\alpha$ determine the location and shape
of the distribution. $x_{m}$ is the minimum possible value.
Figure~\ref{analytic_pareto_cdf} shows CDFs of Pareto
distributions with $x_{m} = 0.5$ and different values
of $\alpha$.
\index{parameter}

\begin{figure}
% analytic.py
%\centerline{\includegraphics[height=2.5in]{figs/analytic_pareto_cdf.pdf}}
\caption{CDFs of Pareto distributions with different parameters.}
\label{analytic_pareto_cdf}
\end{figure}

There is a simple visual test that indicates whether an empirical
distribution fits a Pareto distribution: on a log-log scale, the CCDF
looks like a straight line.  Let's see why that works.

If you plot the CCDF of a sample from a Pareto distribution on a
linear scale, you expect to see a function like:
%
\[ y \approx \left( \frac{x}{x_m} \right) ^{-\alpha} \]
%
Taking the log of both sides yields:
%
\[ \log y \approx -\alpha (\log x - \log x_{m})\]
%
So if you plot $\log y$ versus $\log x$, it should look like a straight
line with slope $-\alpha$ and intercept
$\alpha \log x_{m}$.

As an example, let's look at the sizes of cities and towns.
The U.S.~Census Bureau publishes the
population of every incorporated city and town in the United States.
\index{Pareto distribution} \index{distribution!Pareto}
\index{U.S.~Census Bureau} \index{population} \index{city size}

\begin{figure}
% populations.py
%\centerline{\includegraphics[height=2.5in]{figs/populations_pareto.pdf}}
\caption{CCDFs of city and town populations, on a log-log scale.}
\label{populations_pareto}
\end{figure}

I downloaded their data from
\url{http://www.census.gov/popest/data/cities/totals/2012/SUB-EST2012-3.html};
it is in the repository for this book in a file named
\verb"PEP_2012_PEPANNRES_with_ann.csv".  The repository also
contains {\tt populations.py}, which reads the file and plots
the distribution of populations.

Figure~\ref{populations_pareto} shows the CCDF of populations on a
log-log scale.  The largest 1\% of cities and towns, below $10^{-2}$,
fall along a straight line.  So we could
conclude, as some researchers have, that the tail of this distribution
fits a Pareto model.
\index{model}

On the other hand, a lognormal distribution also models the data well.
Figure~\ref{populations_normal} shows the CDF of populations and a
lognormal model (left), and a normal probability plot (right).  Both
plots show good agreement between the data and the model.
\index{normal probability plot}

Neither model is perfect.
The Pareto model only applies to the largest 1\% of cities, but it
is a better fit for that part of the distribution.  The lognormal
model is a better fit for the other 99\%.
Which model is appropriate depends on which part of the distribution
is relevant.

\begin{figure}
% populations.py
%\centerline{\includegraphics[height=2.5in]{figs/populations_normal.pdf}}
\caption{CDF of city and town populations on a log-x scale (left), and
normal probability plot of log-transformed populations (right).}
\label{populations_normal}
\end{figure}


\section{Generating random numbers}
\index{exponential distribution}
\index{distribution!exponential}
\index{random number}
\index{CDF}
\index{inverse CDF algorithm}
\index{uniform distribution}
\index{distribution!uniform}

Analytic CDFs can be used to generate random numbers with a given
distribution function, $p = \CDF(x)$.  If there is an efficient way to
compute the inverse CDF, we can generate random values
with the appropriate distribution by choosing $p$ from a uniform
distribution between 0 and 1, then choosing
$x = ICDF(p)$.
\index{inverse CDF}
\index{CDF, inverse}

For example, the CDF of the exponential distribution is
%
\[ p = 1 - e^{-\lambda x} \]
%
Solving for $x$ yields:
%
\[ x = -\log (1 - p) / \lambda \]
%
So in Python we can write
%
\begin{verbatim}
def expovariate(lam):
    p = random.random()
    x = -math.log(1-p) / lam
    return x
\end{verbatim}

{\tt expovariate} takes {\tt lam} and returns a random value chosen
from the exponential distribution with parameter {\tt lam}.

Two notes about this implementation:
I called the parameter \verb"lam" because \verb"lambda" is a Python
keyword.  Also, since $\log 0$ is undefined, we have to
be a little careful.  The implementation of {\tt random.random}
can return 0 but not 1, so $1 - p$ can be 1 but not 0, so
{\tt log(1-p)} is always defined.  \index{random module}


\section{Why model?}
\index{model}

At the beginning of this chapter, I said that many real world phenomena
can be modeled with analytic distributions.  ``So,'' you might ask,
``what?''  \index{abstraction}

Like all models, analytic distributions are abstractions, which
means they leave out details that are considered irrelevant.
For example, an observed distribution might have measurement errors
or quirks that are specific to the sample; analytic models smooth
out these idiosyncrasies.
\index{smoothing}

Analytic models are also a form of data compression.  When a model
fits a dataset well, a small set of parameters can summarize a
large amount of data.
\index{parameter}
\index{compression}

It is sometimes surprising when data from a natural phenomenon fit an
analytic distribution, but these observations can provide insight
into physical systems.  Sometimes we can explain why an observed
distribution has a particular form.  For example, Pareto distributions
are often the result of generative processes with positive feedback
(so-called preferential attachment processes: see
\url{http://wikipedia.org/wiki/Preferential_attachment}.).
\index{preferential attachment}
\index{generative process}
\index{Pareto distribution}
\index{distribution!Pareto}
\index{analysis}

Also, analytic distributions lend themselves to mathematical
analysis, as we will see in Chapter~\ref{analysis}.

But it is important to remember that all models are imperfect.
Data from the real world never fit an analytic distribution perfectly.
People sometimes talk as if data are generated by models; for example,
they might say that the distribution of human heights is normal,
or the distribution of income is lognormal.  Taken literally, these
claims cannot be true; there are always differences between the
real world and mathematical models.

Models are useful if they capture the relevant aspects of the
real world and leave out unneeded details.  But what is ``relevant''
or ``unneeded'' depends on what you are planning to use the model
for.


\section{Exercises}

For the following exercises, you can start with \verb"chap05ex.ipynb".
My solution is in \verb"chap05soln.ipynb".

\begin{exercise}
In the BRFSS (see Section~\ref{lognormal}), the distribution of
heights is roughly normal with parameters $\mu = 178$ cm and
$\sigma = 7.7$ cm for men, and $\mu = 163$ cm and $\sigma = 7.3$ cm for
women.
\index{normal distribution}
\index{distribution!normal}
\index{Gaussian distribution}
\index{distribution!Gaussian}
\index{height}
\index{Blue Man Group}
\index{Group, Blue Man}

In order to join Blue Man Group, you have to be male between 5'10''
and 6'1'' (see \url{http://bluemancasting.com}).  What percentage of
the U.S. male population is in this range?  Hint: use {\tt
  scipy.stats.norm.cdf}.
\index{SciPy}

\end{exercise}


\begin{exercise}
To get a feel for the Pareto distribution, let's see how different
the world
would be if the distribution of human height were Pareto.
With the parameters $x_{m} = 1$ m and $\alpha = 1.7$, we
get a distribution with a reasonable minimum, 1 m,
and median, 1.5 m.
\index{height}
\index{Pareto distribution}
\index{distribution!Pareto}

Plot this distribution.  What is the mean human height in Pareto
world?  What fraction of the population is shorter than the mean?  If
there are 7 billion people in Pareto world, how many do we expect to
be taller than 1 km?  How tall do we expect the tallest person to be?
\index{Pareto World}

\end{exercise}


\begin{exercise}
\label{weibull}

The Weibull distribution is a generalization of the exponential
distribution that comes up in failure analysis
(see \url{http://wikipedia.org/wiki/Weibull_distribution}).  Its CDF is
%
\[ CDF(x) = 1 - e^{-(x / \lambda)^k} \]
%
Can you find a transformation that makes a Weibull distribution look
like a straight line?  What do the slope and intercept of the
line indicate?
\index{Weibull distribution}
\index{distribution!Weibull}
\index{exponential distribution}
\index{distribution!exponential}
\index{random module}

Use {\tt random.weibullvariate} to generate a sample from a
Weibull distribution and use it to test your transformation.

\end{exercise}


\begin{exercise}
For small values of $n$, we don't expect an empirical distribution
to fit an analytic distribution exactly.  One way to evaluate
the quality of fit is to generate a sample from an analytic
distribution and see how well it matches the data.
\index{empirical distribution}
\index{distribution!empirical}
\index{random module}

For example, in Section~\ref{exponential} we plotted the distribution
of time between births and saw that it is approximately exponential.
But the distribution is based on only 44 data points.  To see whether
the data might have come from an exponential distribution, generate 44
values from an exponential distribution with the same mean as the
data, about 33 minutes between births.

Plot the distribution of the random values and compare it to the
actual distribution.  You can use {\tt random.expovariate} 
to generate the values.

\end{exercise}

\begin{exercise}
In the repository for this book, you'll find a set of data files
called {\tt mystery0.dat}, {\tt mystery1.dat}, and so on.  Each
contains a sequence of random numbers generated from an analytic
distribution.
\index{random number}

You will also find \verb"test_models.py", a script that reads
data from a file and plots the CDF under a variety of transforms.
You can run it like this:

\begin{verbatim}
$ python test_models.py mystery0.dat
\end{verbatim}

Based on these plots, you should be able to infer what kind of
distribution generated each file.  If you are stumped, you can
look in {\tt mystery.py}, which contains the code that generated
the files.

\end{exercise}


\begin{exercise}
\label{income}

The distributions of wealth and income are sometimes modeled using
lognormal and Pareto distributions.  To see which is better, let's
look at some data.
\index{Pareto distribution}
\index{distribution!Pareto}
\index{lognormal distribution}
\index{distribution!lognormal}

The Current Population Survey (CPS) is a joint effort of the Bureau
of Labor Statistics and the Census Bureau to study income and related
variables.  Data collected in 2013 is available from
\url{http://www.census.gov/hhes/www/cpstables/032013/hhinc/toc.htm}.
I downloaded {\tt hinc06.xls}, which is an Excel spreadsheet with
information about household income, and converted it to {\tt hinc06.csv},
a CSV file you will find in the repository for this book.  You
will also find {\tt hinc.py}, which reads this file.

Extract the distribution of incomes from this dataset.  Are any of the
analytic distributions in this chapter a good model of the data?  A
solution to this exercise is in \url{hinc_soln.py}.
\index{model}

\end{exercise}




\section{Glossary}

\begin{itemize}

\item empirical distribution: The distribution of values in a sample.
  \index{empirical distribution} \index{distribution!empirical}

\item analytic distribution: A distribution whose CDF is an analytic
function.
\index{analytic distribution}
\index{distribution!analytic}

\item model: A useful simplification.  Analytic distributions are
often good models of more complex empirical distributions.
\index{model}

\item interarrival time: The elapsed time between two events.
\index{interarrival time}

\item complementary CDF: A function that maps from a value, $x$,
to the fraction of values that exceed $x$, which is $1 - \CDF(x)$.
\index{complementary CDF} \index{CDF!complementary} \index{CCDF}

\item standard normal distribution: The normal distribution with
mean 0 and standard deviation 1.
\index{standard normal distribution}

\item normal probability plot: A plot of the values in a sample versus
random values from a standard normal distribution.
\index{normal probability plot}
\index{plot!normal probability}

\end{itemize}

