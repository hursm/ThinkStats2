
\chapter{시계열 분석}

{\bf 시계열(time series)}은 시스템에서 시간에 따라 변화하는 측정값 시퀀스다. 
유명한 사례는 ``하키스틱 그래프 (hockey stick graph)''로 시간에 따른 글로벌 평균 기온을 보여준다.(\url{https://en.wikipedia.org/wiki/Hockey_stick_graph} 참조).
\index{시계열 (time series)}
\index{하키스틱 그래프 (hockey stick graph)}

이번 장에서 작업할 예제는 정치과학 연구자 Zachary M. Jones에게서 왔다. 
Zachary는 미국 대마초(마리화나)에 대한 암시장(black market)을 연구한다(\url{http://zmjones.com/marijuana}). ``담배 가격 (Price of Weed)''으로 불리는 웹사이트에서 데이터를 수집했다. 이 웹사이트는 대마초 거래장소, 가격, 품질, 수량을 참여자에게 물어 시장정보를 클라우드 소싱(crowd sourcing)했다(\url{http://www.priceofweed.com/}).
이 프로젝트의 목적은 사장에 대한 합법화(legalization)같은 정책결정 효과를 조사하는 것이다. 이 프로젝트에 매력을 발견했는데 이유는 데이터를 사용해서 중요한 정치적 질문 예를 들면, 약물정책(drug policy)같이 다루기 깨문이다.

\index{담배 가격 (Price of Weed)}
\index{대마초 (cannabis)}

이번 장에서 흥미를 찾았으면하는 희망이 있지만, 분석에 전문가적인 태도를 유지하는 중요성을 반복하는 기회가 되었으면 한다. 약물(drug)가 불법 혹은 어느 약물이 불법이 되어야 하느냐는 중요하고 어려운 공공정책질문이다; 정직하게 보고된 정확한 데이터로 우리의 결정을 통보해야 한다.

\index{윤리 (ethics)}

이번 장에서 사용되는 코드는 {\tt timeseries.py}에 있다.
코드를 다운로드하고 작업하는 것에 대한 정보는 ~\ref{code}을 참조한다.

\section{가져오기(Importing)와 정제하기(cleaning)}

Mr. Jones 사이트에서 다운로드한 데이터는 이책 저장소에 있다.
다음 코드가 데이터를 읽어 판다스 데이터프레임으로 저장한다.
\index{판다스 (pandas)}
\index{데이터프레임 (DataFrame)}

\begin{verbatim}
    transactions = pandas.read_csv('mj-clean.csv', parse_dates=[5])
\end{verbatim}

\verb"parse_dates"는 5번째 칼럼(열)값을 날짜 자료형으로 해석하고, 
넘파이(NumPy) {\tt datetime64} 객체로 전환한다.
\index{넘파이 (NumPy)}

데이터프레임에는 각각 보고된 거래건에 대한 행과 다음 칼럼(열)이 있다.

\begin{itemize}

\item city (도시): 문자열 도시 이름.

\item state (주): 알파벳 두 글자로된 미국 주명.

\item price (가격): 달러로 지불된 가격.
\index{가격 (price)}

\item amount (수량): 그램으로 구입한 수량.

\item quality (품질): 구매자가 보고한 고급, 보통, 저급 품질.

\item date (날짜): 보고날짜, 추측컨데 구매일 직후 날짜.

\item ppg: 달러 표기된 그램당 가격 (price per gram)

\item state.name: 문자열 미국 주 이름

\item lat: 도시 이름에 기반한 거래가 발생한 근사치 위도 정보.

\item lon: 거래가 발생한 근사치 위도 정보.

\end{itemize}

거래 각각은 시간에 따라 발생한 사건(event)으로, 이 데이터셋을 시계열 자료로 처리할 수 있다. 하지만, 사건이 시간에 균등하게 발생하는 것은 아니다; 각 날짜별로 보고된 거래 숫자는 0건 에서 수백건으로 다양한다. 시계열을 분석하는데 사용되는 많은 방법은 측정값이 균등하게 간격으로 되어있어야 한다. 혹은 만약 데이터가 동일 간격이라면 더 간단하다.

\index{거래 (transaction)}
\index{동일 간격 데이터 (equally spaced data)}

이 방법을 시연하기 위해서, 데이터셋을 대마초 품질을 보고한 집단으로 나눈다. 그리고 나서 그램당 일별 평균 가격을 계산해서 각 집단을 동일 가격 계열(equally spaced series)로 변환한다.

\begin{verbatim}
def GroupByQualityAndDay(transactions):
    groups = transactions.groupby('quality')
    dailies = {}
    for name, group in groups:
        dailies[name] = GroupByDay(group)        

    return dailies
\end{verbatim}

{\tt groupby}는 GroupBy 객체를 반환하는 데이터프레임 메쏘드다; for 루프에 사용되서, 집단 이름과 집단을 표현하는 데이터프레임을 반복한다.
{\tt quality}가 {\tt low}, {\tt medium}, {\tt high}이기 때문에 이 이름을 갖는 집단 세개를 얻는다.

루프는 집단을 반복하는데 {\tt GroupByDay}를 호출해서 일별 평균 가격을 계산하고, 새로운 데이터프레임을 반환한다.

\begin{verbatim}
def GroupByDay(transactions, func=np.mean):
    grouped = transactions[['date', 'ppg']].groupby('date')
    daily = grouped.aggregate(func)

    daily['date'] = daily.index
    start = daily.date[0]
    one_year = np.timedelta64(1, 'Y')
    daily['years'] = (daily.date - start) / one_year

    return daily
\end{verbatim}

모수 {\tt transactions}은 데이터프레임으로 {\tt date}와 {\tt ppg}칼럼을 포함하는 데이터프레임이다. 칼럼을 두개 선택하고 나서, {\tt date} 별로 묶는다.
\index{groupby}

{\tt grouped} 결과는 날짜별로 데이터프레임으로 매핑하는데, 그 날짜에 보고된 가격을 담고 있다. {\tt aggregate}는 GroupBy 메쏘드로 집단을 반복하고, 함수를 집단 각 칼럼에 적용한다; 이 경우 칼럼은 {\tt ppg} 하나다.
그래서 {\tt aggregate} 결과는 각 날짜에 대해 행 하나와 한 칼럼 {\tt ppg}을 갖는 데이터프레임이다.
\index{aggregate}

데이터프레임에 날짜는 넘파이(NumPy) {\tt datetime64} 객체로 저장되어 있는데 10억분의 1초(nanoseconds) 64-비트 정수로 표현된다.
다음 분석을 위해서, 년도처럼 사람이 읽기 쉬운 단위로 시간 정보를 작업하는 것이 편리할 것이다. 그래서, {\tt GroupByDay}는 {\tt index}를 복사해서 {\tt date}라는 칼럼을 추가하고 나서, {\tt years}를 추가하는데 부동소수점 형식으로 첫 거래 이후로 년도 숫자를 담고 있다.
\index{넘파이 (NumPy)}
\index{datetime64}

최종결과 데이터프레임에는 {\tt ppg}, {\tt date}, {\tt years} 칼럼이 있다.
\index{데이터프레임 (DataFrame)}


\section{플롯 그리기 (Plotting)}

{\tt GroupByQualityAndDay} 결과는 각 대마초 품질로부터 일별 가격 데이터프레임으로 매핑이다. 다음에 시계열 세개를 플롯으로 그리는 코드가 있다.
\index{데이터프레임 (DataFrame)}
\index{시각화 (visualization)}

\begin{verbatim}
    thinkplot.PrePlot(rows=3)
    for i, (name, daily) in enumerate(dailies.items()):
        thinkplot.SubPlot(i+1)
        title = 'price per gram ($)' if i==0 else ''
        thinkplot.Config(ylim=[0, 20], title=title)
        thinkplot.Scatter(daily.index, daily.ppg, s=10, label=name)
        if i == 2: 
            pyplot.xticks(rotation=30)
        else:
            thinkplot.Config(xticks=[])
\end{verbatim}

{\tt rows=3}을 갖는 {\tt PrePlot}은 세개 하위그림(subplot)을 3행에 걸쳐 플롯을 그릴려고 한다는 것을 의미한다.
루프가 데이터프레임을 반복하면서 각각에 대해 산점도를 생성한다.
시계열 데이터를 플롯 그림으로 그릴 때 점들 사이를 선분(line segment)으로 표현하는 것이 일반적이다. 하지만, 이 경우에는 데이터 점이 많고, 가격 변동성이 크기 때문에, 선분을 추가는 것이 그다지 도움이 되지 못한다.
\index{thinkplot}

x-축에 라벨이 날짜라서, 가독성을 좋게 하려고 {\tt pyplot.xticks} 을 사용해서 ``ticks''을 30도 회전한다.

\index{pyplot}
\index{ticks}
\index{xticks}

\begin{figure}
% timeseries.py
\centerline{\includegraphics[width=3.5in]{figs/timeseries1.pdf}}
\caption{Time series of daily price per gram for high, medium, and low
quality cannabis.}
\label{timeseries1}
\end{figure}

그림~\ref{timeseries1}에 결과가 나와있다.
이 플롯 그림을 통해서 한가지 명백한 특징은 2013년 11월 틈이 있다는 것이다.
데이터 수집이 이 기간동안 활발하지 못하거나, 데이터가 이용가능하지 않았다는 것도 가능하다. 나중에 결측 데이터를 처리하는 방법을 생각해볼 것이다.
\index{결측값 (missing values)}

시각적으로 고품질 대마초 가격이 이 기간동안 하락하는 것처럼 보인다. 저품질 대마초 가격은 상승하는 것처럼 보이지만, 식별하기는 어렵다. 왜냐하면 변동성이 더 크기 때문이다. 품질 데이터는 자발적으로 보고한 것으로 시간에 따른 경향에는 참여자가 어떻게 품질 라벨을 적용했는지에 대한변동이 반영된다는 것을 기억하라.
\index{가격 (price)}


\section{선형 회귀 (Linear regression)}
\label{timeregress}

시계열분석에 특화된 방법론이 있지만, 많은 문제에 대해서, 시작하기 좋은 단순한 방법은 선형 회귀같은 범용 도구를 적용해보는 것이다.
다음 함수는 일별 가격 정보 데이터프레임을 받아서, 최소제곱 적합을 계산한다. StatsModels에서 모형과 결과 객체를 반환한다.

\index{데이터프레임 (DataFrame)}
\index{StatsModels}
\index{선형 회귀 (linear regression)}

\begin{verbatim}
def RunLinearModel(daily):
    model = smf.ols('ppg ~ years', data=daily)
    results = model.fit()
    return model, results
\end{verbatim}

그리고 나서, 수량을 반복하고 각각 모형에 적합한다.

\begin{verbatim}
    for name, daily in dailies.items():
        model, results = RunLinearModel(daily)
        print(name)
        regression.SummarizeResults(results)
\end{verbatim}

다음에 결과가 나와있다.

\begin{center}
\begin{tabular}{|l|l|l|c|} \hline
quality & intercept & slope & $R^2$ \\ \hline
high    & 13.450  & -0.708  & 0.444 \\
medium  &  8.879  & 0.283   & 0.050 \\
low     &  5.362  & 0.568   & 0.030 \\
\hline
\end{tabular}
\end{center}

추정된 기울기는 고품질 대마초 가격이 관측구간에서 매년 약 71 센트 하락했다; 중간 품질 대마초에 대해서는 매년 약 28 센트 층가했고, 저급 품질 대마초에 대해서는 매년 약 57 센트 증가했다. 이러한 추정값은 매우 작은 p-값으로 모두 통계적으로 유의하다.

\index{p-값 (p-value)}
  \index{유의성 (significant)} 
  \index{통계적 유의성 (statistically significant)}

고품질 대마초에 대한 $R^2$ 값은 0.44로 설명변수로서 시간이 관측된 가격 변동성의 44\%를 설명한다.
다른 대마초 품질에 대해서는 가격 변동이 더 작고, 가격에 변동성이 더 커서, $R^2$ 값이 더 작다(하지만, 여전히 통계적 유의성이 있다.)
\index{설명 변수 (explanatory variable)}
  \index{통계적 유의성 (statistically significant)}

다음 코드는 관측 가격과 적합값(fitted value)을 플롯으로 그린다.

\begin{verbatim}
def PlotFittedValues(model, results, label=''):
    years = model.exog[:,1]
    values = model.endog
    thinkplot.Scatter(years, values, s=15, label=label)
    thinkplot.Plot(years, results.fittedvalues, label='model')
\end{verbatim}

~\ref{implementation} 절에서 보았듯이, {\tt model}에는 {\tt exog}, {\tt endog}, 넘파이(NumPy)배열이 외생(설명), 내생(종속) 변수로 포함된다.
\index{넘파이 (NumPy)}
\index{설명변수 (explanatory variable)}
\index{종속변수 (dependent variable)}
\index{외생변수 (exogenous variable)}
\index{내생변수 (endogenous variable)}

\begin{figure}
% timeseries.py
\centerline{\includegraphics[height=2.5in]{figs/timeseries2.pdf}}
\caption{Time series of daily price per gram for high quality cannabis,
and a linear least squares fit.}
\label{timeseries2}
\end{figure}

{\tt PlotFittedValues}은 데이터 점을 산점도로, 적합값을 선형 플롯 그림으로 만든다. 그림~\ref{timeseries2}에는 고품질 대마초에 대해 플롯을 그린 결과가 있다. 모형이 데이터에 대한 좋은 선형 적합처럼 보인다; 하지만, 선형회귀는 이러한 데이터에 대해서 가장 적절한 선택은 아니다.
\index{모형 (model)}
\index{적합값 (fitted values)}

\begin{itemize}

\item 첫째로, 장기 추세를 선형 혹은 다른 간단한 함수로 예측할 이유가 없다.
일반적으로, 가격은 수요와 공급에 의해 결정된다. 모두 시간에 따라 예측불가한 방향으로 변화한다.
\index{추세 (trend)}

\item 둘째, 선형회귀모형은 모든 데이터 (최근 혹은 과거)에 대해 동일한 가중치를 둔다. 예측 목적으로, 아마도 최근 데이터에 더 많은 가중치를 두어야 한다.
\index{가중치 (weight)}

\item 마지막으로, 선형회귀 가정중의 하나는 잔차가 상관되지 않는 잡음이라는 것이다. 시계열 데이터에서 연속된 값이 상관되기 때문에 종종 이런 가정은 틀리다. 
\index{잔차 (residuals)}

\end{itemize}

다음 절에서 대안을 제시하는 시계열 데이터에 대해서 더 적절하다.

\section{이동 평균 (Moving averages)}

대부분 시계열 분석은 관측된 계열이 다음 세가지 요소 합이라는 모형화 가정에 기반한다.

\index{모형 (model)}
\index{이동 평균 (moving average)}

\begin{itemize}

\item 추세 (Trend): 지속되는 변경사항을 잡아내는 평활 함수 (smooth function).
\index{추세 (trend)}

\item 계절성 (Seasonality): 주기적 변동, 아마도 일별, 주별, 월별, 혹은 년별 사이클.
\index{계절성 (seasonality)}

\item 잡음 (Noise): 장기 추세 주위 확률 변동.
\index{잡음 (noise)}

\end{itemize}

앞절에서 살펴봤듯이, 회귀는 계열에서 추세를 뽑아내는 한 방법이다. 하지만, 추세는 단순한 함수가 아니다. 훌륭한 대안은 {\bf 이동평균(moving average)}이다. 이동평균은 계열을 {\bf 윈도우(windows)}로 불리는 겹치지 않는 지역으로 나누고 각 윈도우에 있는 값을 평균낸다.
\index{윈도우 (window)}

가장 단순한 이동평균 중의 하나는 {\bf 이동평균 (rolling mean)}이다. 각 윈도우에 있는 값을 평균낸다. 예를 들어, 만약 윈도우 크기가 3이라면, 이동 평균은 0에서 2까지, 1에서 3까지, 2에서 4까지 등등 사이에 있는 값을 평균낸다.

\index{이동평균 (rolling mean)}
\index{평균 (mean)!이동 (rolling)}

판다스는에는 \verb"rolling_mean"가 있는데, 시리즈와 윈도우 크기를 인자로 받아 새로운 시리즈를 반환한다.
\index{판다스 (pandas)}
\index{시리즈 (Series)}

\begin{verbatim}
>>> series = np.arange(10)
array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])

>>> pandas.rolling_mean(series, 3)
array([ nan,  nan,   1,   2,   3,   4,   5,   6,   7,   8])
\end{verbatim}

첫 두값은 {\tt nan}이다; 다음 값은 첫 세 요소(0,1,2) 평균이다.
다음 값은 1,2,3의 평균. 등등

대마초 데이터에 \verb"rolling_mean"을 적용하기 전에, 결측값을 다루어야 한다. 하나 혹은 그 이상 대마초 품질 범주에 대해서, 관측 구간에 보고되지 않은 거래가 있는 몇일이 있고 데이터 수집이 활성화되지 않은 2013년 특정 기간이 있다.

\index{결측값 (missing values)}

지금까지 사용한 데이터프레임에 상기 날짜는 비워져있다; 인덱스는 데이터에 없는 날은 건너뛴다. 다음 분석에 대해서, 결측 데이터를 명시적으로 표기할 필요가 있다. 데이터프레임을 ``다시 인덱싱(reindexing)''해서 이 작업을 수행한다.
 \index{데이터프레임 (DataFrame)}
\index{reindex}

\begin{verbatim}
    dates = pandas.date_range(daily.index.min(), daily.index.max())
    reindexed = daily.reindex(dates)
\end{verbatim}

첫번째 행은 관측 구간 처음부터 끝까지 모든 날을 포함하는 날짜 범위를 계산한다. 두번째 행은 {\tt daily}로부터 모든 데이터를 갖는 새로운 데이터프레임을 생성하지만, {\tt nan}으로 채워진 모든 날째 행 열을 포함한다.

\index{구간 (interval)}
\index{날짜 범위 (date range)}

이제, 다음과 같이 이동평균 플롯을 그릴 수 있다.

\begin{verbatim}
    roll_mean = pandas.rolling_mean(reindexed.ppg, 30)
    thinkplot.Plot(roll_mean.index, roll_mean)
\end{verbatim}

윈도우 크기는 30이고, \verb"roll_mean"에 있는 각 값은 {\tt reindexed.ppg}으로부터 30 개값의 평균이다.

\index{판다스 (pandas)}
\index{윈도우 (window)}

\begin{figure}
% timeseries.py
\centerline{\includegraphics[height=2.5in]{figs/timeseries10.pdf}}
\caption{Daily price and a rolling mean (left) and exponentially-weighted
moving average (right).}
\label{timeseries10}
\end{figure}

그림~\ref{timeseries10} (왼편)에 결과가 그려져 있다.
이동평균은 잡음을 평활하고 추세를 추출하는 작업을 잘 하는 것처럼 보인다. 
첫 29개 값은 {\tt nan} 이고, 결측값이 있는 곳에, 또다른 {\tt nan} 29개가 다음에 있다. 이런 틈을 매울 수 있는 방법이 몇개 있지만, 성가신 작은 일이다.
\index{결측값 (missing values)}
\index{잡음 (noise)}
\index{평활 (smoothing)}

대안은 {\bf 지수가중 이동평균 (exponentially-weighted moving average)}으로 두가지 장점이 있다. 첫째, 이름에서 암시하듯이, 가중평균을 계산하는데 가장 최근 값에 가장 높은 가중치를 두고 이전 값의 가중치는 지수적으로 하락한다. 두번째, EWMA 판다스 구현이 결측값을 더 잘 처리한다.
\index{reindex}
\index{지수가중 이동평균 (exponentially-weighted moving average)}
\index{EWMA}

\begin{verbatim}
    ewma = pandas.ewma(reindexed.ppg, span=30)
    thinkplot.Plot(ewma.index, ewma)
\end{verbatim}

{\bf span} 모수는 대략 이동평균 윈도우 크기에 상응한다; 가중치가 얼마나 빨리 감쇄하는지 제어한다. 그래서 각 평균값에 무시못할 기여를 하는 점의 갯수를 결정한다.
\index{span}
\index{윈도우 (window)}

그림~\ref{timeseries10} (오른편)에 동일한 데이터에 대한 EWMA가 그려져 있다. 둘다 정의된 지점에서는 이동평균과 비슷하다. 하지만, 결측값이 없는데 작업하기 더 수월하게 한다. 시계열 시작부근에서 값들이 잡음이 있어 보이는데, 좀더 적은 데이터 점에 모형이 기반하기 때문이다.
\index{결측값 (missing values)}


\section{Missing values}

Now that we have characterized the trend of the time series, the
next step is to investigate seasonality, which is periodic behavior.
Time series data based on human behavior often exhibits daily,
weekly, monthly, or yearly cycles.  In the next section I present
methods to test for seasonality, but they don't work well with
missing data, so we have to solve that problem first.
\index{missing values}
\index{seasonality}

A simple and common way to fill missing data is to use a moving
average.  The Series method {\tt fillna} does just what we want:
\index{Series}
\index{fillna}

\begin{verbatim}
    reindexed.ppg.fillna(ewma, inplace=True)
\end{verbatim}

Wherever {\tt reindexed.ppg} is {\tt nan}, {\tt fillna} replaces
it with the corresponding value from {\tt ewma}.  The {\tt inplace}
flag tells {\tt fillna} to modify the existing Series rather than
create a new one.

A drawback of this method is that it understates the noise in the
series.  We can solve that problem by adding in resampled
residuals:
\index{resampling}
\index{noise}

\begin{verbatim}
    resid = (reindexed.ppg - ewma).dropna()
    fake_data = ewma + thinkstats2.Resample(resid, len(reindexed))
    reindexed.ppg.fillna(fake_data, inplace=True)
\end{verbatim}

% (One note on vocabulary: in this book I am using
%``resampling'' in the statistical sense, which is drawing a random
%sample from a population that is, itself, a sample.  In the context
%of time series analysis, it has another meaning: changing the
%time between measurements in a series.  I don't use the second
%meaning in this book, but you might encounter it.)

{\tt resid} contains the residual values, not including days
when {\tt ppg} is {\tt nan}.  \verb"fake_data" contains the
sum of the moving average and a random sample of residuals.
Finally, {\tt fillna} replaces {\tt nan} with values from
\verb"fake_data".
\index{dropna}
\index{fillna}
\index{NaN}

\begin{figure}
% timeseries.py
\centerline{\includegraphics[height=2.5in]{figs/timeseries8.pdf}}
\caption{Daily price with filled data.}
\label{timeseries8}
\end{figure}

Figure~\ref{timeseries8} shows the result.  The filled data is visually
similar to the actual values.  Since the resampled residuals are
random, the results are different every time; later we'll see how
to characterize the error created by missing values.
\index{resampling}
\index{missing values}


\section{Serial correlation}

As prices vary from day to day, you might expect to see patterns.
If the price is high on Monday,
you might expect it to be high for a few more days; and
if it's low, you might expect it to stay low.  A pattern
like this is called {\bf serial
correlation}, because each value is correlated with the next one
in the series.
\index{correlation!serial}
\index{serial correlation}

To compute serial correlation, we can shift the time series
by an interval called a {\bf lag}, and then compute the correlation
of the shifted series with the original:
\index{lag}

\begin{verbatim}
def SerialCorr(series, lag=1):
    xs = series[lag:]
    ys = series.shift(lag)[lag:]
    corr = thinkstats2.Corr(xs, ys)
    return corr
\end{verbatim}

After the shift, the first {\tt lag} values are {\tt nan}, so
I use a slice to remove them before computing {\tt Corr}.
\index{NaN}

%high 0.480121816154
%medium 0.164600078362
%low 0.103373620131

If we apply {\tt SerialCorr} to the raw price data with lag 1, we find
serial correlation 0.48 for the high quality category, 0.16 for
medium and 0.10 for low.  In any time series with a long-term trend,
we expect to see strong serial correlations; for example, if prices
are falling, we expect to see values above the mean in the first
half of the series and values below the mean in the second half.

It is more interesting to see if the correlation persists if you
subtract away the trend.  For example, we can compute the residual
of the EWMA and then compute its serial correlation:
\index{EWMA}

\begin{verbatim}
    ewma = pandas.ewma(reindexed.ppg, span=30)
    resid = reindexed.ppg - ewma
    corr = SerialCorr(resid, 1)
\end{verbatim}

With lag=1, the serial correlations for the de-trended data are
-0.022 for high quality, -0.015 for medium, and 0.036 for low.
These values are small, indicating that there is little or
no one-day serial correlation in this series.
\index{pandas}

To check for weekly, monthly, and yearly seasonality, I ran
the analysis again with different lags.  Here are the results:
\index{seasonality}

\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
lag & high & medium & low \\ \hline
1 & -0.029 & -0.014 & 0.034 \\
7 & 0.02 & -0.042 & -0.0097 \\
30 & 0.014 & -0.0064 & -0.013 \\
365 & 0.045 & 0.015 & 0.033 \\
\hline
\end{tabular}
\end{center}

In the next section we'll test whether these correlations are
statistically significant (they are not), but at this point we can
tentatively conclude that there are no substantial seasonal patterns
in these series, at least not with these lags.
  \index{significant} \index{statistically significant}


\section{Autocorrelation}

If you think a series might have some serial correlation, but you
don't know which lags to test, you can test them all!  The {\bf
  autocorrelation function} is a function that maps from lag to the
serial correlation with the given lag.  ``Autocorrelation'' is another
name for serial correlation, used more often when the lag is not 1.
\index{autocorrelation function}

StatsModels, which we used for linear regression in
Section~\ref{statsmodels}, also provides functions for time series
analysis, including {\tt acf}, which computes the autocorrelation
function:
\index{StatsModels}

\begin{verbatim}
    import statsmodels.tsa.stattools as smtsa
    acf = smtsa.acf(filled.resid, nlags=365, unbiased=True)
\end{verbatim}

{\tt acf} computes serial correlations with
lags from 0 through {\tt nlags}.  The {\tt unbiased} flag tells
{\tt acf} to correct the estimates for the sample size.  The result
is an array of correlations.  If we select daily prices for high
quality, and extract correlations for lags 1, 7, 30, and 365, we can
confirm that {\tt acf} and {\tt SerialCorr} yield approximately
the same results:
\index{acf}

\begin{verbatim}
>>> acf[0], acf[1], acf[7], acf[30], acf[365]
1.000, -0.029, 0.020, 0.014, 0.044
\end{verbatim}

With {\tt lag=0}, {\tt acf} computes the correlation of the series
with itself, which is always 1.
\index{lag}

\begin{figure}
% timeseries.py
\centerline{\includegraphics[height=2.5in]{figs/timeseries9.pdf}}
\caption{Autocorrelation function for daily prices (left), and
daily prices with a simulated weekly seasonality (right).}
\label{timeseries9}
\end{figure}

Figure~\ref{timeseries9} (left) shows autocorrelation functions for
the three quality categories, with {\tt nlags=40}.  The gray region
shows the normal variability we would expect if there is no actual
autocorrelation; anything that falls outside this range is
statistically significant, with a p-value less than 5\%.  Since
the false positive rate is 5\%, and
we are computing 120 correlations (40 lags for each of 3 times series),
we expect to see about 6 points outside this region.  In fact, there
are 7.  We conclude that there are no autocorrelations
in these series that could not be explained by chance.
\index{p-value}
  \index{significant} \index{statistically significant}
\index{false positive}

I computed the gray regions by resampling the residuals.  You
can see my code in {\tt timeseries.py}; the function is called
{\tt SimulateAutocorrelation}.
\index{resampling}

To see what the autocorrelation function looks like when there is a
seasonal component, I generated simulated data by adding a weekly
cycle.  Assuming that demand for cannabis is higher on weekends, we
might expect the price to be higher.  To simulate this effect, I
select dates that fall on Friday or Saturday and add a random amount
to the price, chosen from a uniform distribution from \$0 to \$2.
\index{simulation}
\index{uniform distribution}
\index{distribution!uniform}

\begin{verbatim}
def AddWeeklySeasonality(daily):
    frisat = (daily.index.dayofweek==4) | (daily.index.dayofweek==5)
    fake = daily.copy()
    fake.ppg[frisat] += np.random.uniform(0, 2, frisat.sum())
    return fake
\end{verbatim}

{\tt frisat} is a boolean Series, {\tt True} if the day of the
week is Friday or Saturday.  {\tt fake} is a new DataFrame, initially
a copy of {\tt daily}, which we modify by adding random values
to {\tt ppg}.  {\tt frisat.sum()} is the total number of Fridays
and Saturdays, which is the number of random values we have to
generate.
\index{DataFrame}
\index{Series}
\index{boolean}

Figure~\ref{timeseries9} (right) shows autocorrelation functions for
prices with this simulated seasonality.  As expected, the
correlations are highest when the lag is a multiple of 7.  For
high and medium quality, the new correlations are statistically
significant.  For low quality they are not, because residuals in this
category are large; the effect would have to be bigger
to be visible through the noise.
  \index{significant} \index{statistically significant}
\index{residuals}
\index{lag}


\section{Prediction}  

Time series analysis can be used to investigate, and sometimes
explain, the behavior of systems that vary in time.  It can also
make predictions.
\index{prediction}

The linear regressions we used in Section~\ref{timeregress} can be
used for prediction.  The RegressionResults class provides {\tt
  predict}, which takes a DataFrame containing the explanatory
variables and returns a sequence of predictions.  Here's the code:
\index{explanatory variable}
\index{linear regression}

\begin{verbatim}
def GenerateSimplePrediction(results, years):
    n = len(years)
    inter = np.ones(n)
    d = dict(Intercept=inter, years=years)
    predict_df = pandas.DataFrame(d)
    predict = results.predict(predict_df)
    return predict
\end{verbatim}

{\tt results} is a RegressionResults object; {\tt years} is the
sequence of time values we want predictions for.  The function
constructs a DataFrame, passes it to {\tt predict}, and
returns the result.
\index{pandas}
\index{DataFrame}

If all we want is a single, best-guess prediction, we're done.  But
for most purposes it is important to quantify error.  In other words,
we want to know how accurate the prediction is likely to be.

There are three sources of error we should take into account:

\begin{itemize}

\item Sampling error: The prediction is based on estimated
parameters, which depend on random variation
in the sample.  If we run the experiment again, we expect
the estimates to vary.
\index{sampling error}
\index{parameter}

\item Random variation:  Even if the estimated parameters are
perfect, the observed data varies randomly around the long-term
trend, and we expect this variation to continue in the future.
\index{noise}

\item Modeling error: We have already seen evidence that the long-term
trend is not linear, so predictions based on a linear model will
eventually fail.  
\index{modeling error}

\end{itemize}

Another source of error to consider is unexpected future events.
Agricultural prices are affected by weather, and all prices are
affected by politics and law.  As I write this, cannabis is legal in
two states and legal for medical purposes in 20 more.  If more states
legalize it, the price is likely to go down.  But if
the federal government cracks down, the price might go up.

Modeling errors and unexpected future events are hard to quantify.
Sampling error and random variation are easier to deal with, so we'll
do that first.

To quantify sampling error, I use resampling, as we did in
Section~\ref{regest}.  As always, the goal is to use the actual
observations to simulate what would happen if we ran the experiment
again.  The simulations are based on the assumption that the estimated
parameters are correct, but the random residuals could have been
different.  Here is a function that runs the simulations:
\index{resampling}

\begin{verbatim}
def SimulateResults(daily, iters=101):
    model, results = RunLinearModel(daily)
    fake = daily.copy()
    
    result_seq = []
    for i in range(iters):
        fake.ppg = results.fittedvalues + Resample(results.resid)
        _, fake_results = RunLinearModel(fake)
        result_seq.append(fake_results)

    return result_seq
\end{verbatim}

{\tt daily} is a DataFrame containing the observed prices;
{\tt iters} is the number of simulations to run.
\index{DataFrame}
\index{price}

{\tt SimulateResults} uses {\tt RunLinearModel}, from
Section~\ref{timeregress}, to estimate the slope and intercept
of the observed values.

Each time through the loop, it generates a ``fake'' dataset by
resampling the residuals and adding them to the fitted values.  Then
it runs a linear model on the fake data and stores the RegressionResults
object.
\index{model}
\index{residuals}

The next step is to use the simulated results to generate predictions:

\begin{verbatim}
def GeneratePredictions(result_seq, years, add_resid=False):
    n = len(years)
    d = dict(Intercept=np.ones(n), years=years, years2=years**2)
    predict_df = pandas.DataFrame(d)
    
    predict_seq = []
    for fake_results in result_seq:
        predict = fake_results.predict(predict_df)
        if add_resid:
            predict += thinkstats2.Resample(fake_results.resid, n)
        predict_seq.append(predict)

    return predict_seq
\end{verbatim}

{\tt GeneratePredictions} takes the sequence of results from the
previous step, as well as {\tt years}, which is a sequence of
floats that specifies the interval to generate predictions for,
and \verb"add_resid", which indicates whether it should add resampled
residuals to the straight-line prediction.
{\tt GeneratePredictions} iterates through the sequence of
RegressionResults and generates a sequence of predictions.
\index{resampling}

\begin{figure}
% timeseries.py
\centerline{\includegraphics[height=2.5in]{figs/timeseries4.pdf}}
\caption{Predictions based on linear fits, showing variation due
to sampling error and prediction error.}
\label{timeseries4}
\end{figure}

Finally, here's the code that plots a 90\% confidence interval for
the predictions:
\index{confidence interval}

\begin{verbatim}
def PlotPredictions(daily, years, iters=101, percent=90):
    result_seq = SimulateResults(daily, iters=iters)
    p = (100 - percent) / 2
    percents = p, 100-p

    predict_seq = GeneratePredictions(result_seq, years, True)
    low, high = thinkstats2.PercentileRows(predict_seq, percents)
    thinkplot.FillBetween(years, low, high, alpha=0.3, color='gray')

    predict_seq = GeneratePredictions(result_seq, years, False)
    low, high = thinkstats2.PercentileRows(predict_seq, percents)
    thinkplot.FillBetween(years, low, high, alpha=0.5, color='gray')
\end{verbatim}

{\tt PlotPredictions} calls {\tt GeneratePredictions} twice: once
with \verb"add_resid=True" and again with \verb"add_resid=False".
It uses {\tt PercentileRows} to select the 5th and 95th percentiles
for each year, then plots a gray region between these bounds.
\index{FillBetween}

Figure~\ref{timeseries4} shows the result.
The dark gray region represents a 90\% confidence interval for
the sampling error; that is, uncertainty about the estimated
slope and intercept due to sampling.
\index{sampling error}

The lighter region shows
a 90\% confidence interval for prediction error, which is the
sum of sampling error and random variation.
\index{noise}

These regions quantify sampling error and random variation, but
not modeling error.  In general modeling error is hard to quantify,
but in this case we can address at least one source of error,
unpredictable external events.
\index{modeling error}

The regression model is based on the assumption that the system
is {\bf stationary}; that is, that the parameters of the model
don't change over time.
Specifically, it assumes that the slope and
intercept are constant, as well as the distribution of residuals.
\index{stationary model}
\index{parameter}

But looking at the moving averages in Figure~\ref{timeseries10}, it
seems like the slope changes at least once during the observed
interval, and the variance of the residuals seems bigger in the first
half than the second.
\index{slope}

As a result, the parameters we get depend on the interval we
observe.  To see how much effect this has on the predictions,
we can extend {\tt SimulateResults} to use intervals of observation
with different start and end dates.  My implementation is in
{\tt timeseries.py}.
\index{simulation}

\begin{figure}
% timeseries.py
\centerline{\includegraphics[height=2.5in]{figs/timeseries5.pdf}}
\caption{Predictions based on linear fits, showing
variation due to the interval of observation.}
\label{timeseries5}
\end{figure}

Figure~\ref{timeseries5} shows the result for the medium quality
category.  The lightest gray area shows a confidence interval that
includes uncertainty due to sampling error, random variation, and
variation in the interval of observation.
\index{confidence interval}
\index{interval}

The model based on the entire interval has positive slope, indicating
that prices were increasing.  But the most recent interval shows signs
of decreasing prices, so models based on the most recent data have
negative slope.  As a result, the widest predictive interval includes
the possibility of decreasing prices over the next year.
\index{model}


\section{Further reading}

Time series analysis is a big topic; this chapter has only scratched
the surface.  An important tool for working with time series data
is autoregression, which I did not cover here, mostly because it turns
out not to be useful for the example data I worked with.
\index{time series}

But once you
have learned the material in this chapter, you are well prepared
to learn about autoregression.  One resource I recommend is
Philipp Janert's book, {\it Data Analysis with Open Source Tools},
O'Reilly Media, 2011.  His chapter on time series analysis picks up
where this one leaves off.
\index{Janert, Philipp}


\section{Exercises}

My solution to these exercises is in \verb"chap12soln.py".

\begin{exercise}
The linear model I used in this chapter has the obvious drawback
that it is linear, and there is no reason to expect prices to
change linearly over time.
We can add flexibility to the model by adding a quadratic term,
as we did in Section~\ref{nonlinear}.  
\index{nonlinear}
\index{linear model}
\index{quadratic model}

Use a quadratic model to fit the time series of daily prices,
and use the model to generate predictions.  You will have to
write a version of {\tt RunLinearModel} that runs that quadratic
model, but after that you should be able to reuse code in
{\tt timeseries.py} to generate predictions.
\index{prediction}

\end{exercise}

\begin{exercise}
Write a definition for a class named {\tt SerialCorrelationTest}
that extends {\tt HypothesisTest} from Section~\ref{hypotest}.
It should take a series and a lag as data, compute the serial
correlation of the series with the given lag, and then compute
the p-value of the observed correlation.
\index{HypothesisTest}
\index{p-value}
\index{lag}

Use this class to test whether the serial correlation in raw
price data is statistically significant.  Also test the residuals
of the linear model and (if you did the previous exercise),
the quadratic model.
\index{quadratic model}
  \index{significant} \index{statistically significant}

\end{exercise}

\begin{exercise}
There are several ways to extend the EWMA model to generate predictions.
One of the simplest is something like this:
\index{EWMA}

\begin{enumerate}

\item Compute the EWMA of the time series and use the last point
as an intercept, {\tt inter}.

\item Compute the EWMA of differences between successive elements in
the time series and use the last point as a slope, {\tt slope}.
\index{slope}

\item To predict values at future times, compute {\tt inter + slope * dt},
where {\tt dt} is the difference between the time of the prediction and
the time of the last observation.
\index{prediction}

\end{enumerate}

Use this method to generate predictions for a year after the last
observation.  A few hints:

\begin{itemize}

\item Use {\tt timeseries.FillMissing} to fill in missing values
before running this analysis.  That way the time between consecutive
elements is consistent.
\index{missing values}

\item Use {\tt Series.diff} to compute differences between successive
elements.
\index{Series}

\item Use {\tt reindex} to extend the DataFrame index into the future.
\index{reindex}

\item Use {\tt fillna} to put your predicted values into the DataFrame.
\index{fillna}

\end{itemize}

\end{exercise}


\section{Glossary}

\begin{itemize}

\item time series: A dataset where each value is associated with
a timestamp, often a series of measurements and the times they
were collected.
\index{time series}

\item window: A sequence of consecutive values in a time series,
often used to compute a moving average.
\index{window}

\item moving average: One of several statistics intended to estimate
the underlying trend in a time series by computing averages (of
some kind) for a series of overlapping windows.
\index{moving average}

\item rolling mean: A moving average based on the mean value in
each window.
\index{rolling mean}

\item exponentially-weighted moving average (EWMA): A moving
average based on a weighted mean that gives the highest weight
to the most recent values, and exponentially decreasing weights
to earlier values.
\index{exponentially-weighted moving average}
\index{EWMA}

\item span: A parameter of EWMA that determines how quickly the
weights decrease.
\index{span}

\item serial correlation: Correlation between a time series and
a shifted or lagged version of itself.
\index{serial correlation}

\item lag: The size of the shift in a serial correlation or
autocorrelation.
\index{lag}

\item autocorrelation: A more general term for a serial correlation
with any amount of lag.
\index{autocorrelation function}

\item autocorrelation function: A function that maps from lag to
serial correlation.

\item stationary: A model is stationary if the parameters and the
distribution of residuals does not change over time.
\index{model}
\index{stationary model}

\end{itemize}

